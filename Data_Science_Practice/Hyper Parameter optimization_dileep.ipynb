{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Life cycle of a Data science project\n",
    "1. Data collection\n",
    "2. Feature Engineering\n",
    "3. Feature Selection\n",
    "4. Model creation\n",
    "5. Hyper parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All techniques of Hyper parameter Optimization\n",
    " \n",
    "    1. GridsearchCV\n",
    "    2. RandamizedSearchCV\n",
    "    3. Bayesian Optimization - Automate Hyperparameter Tuning(Hyperopt)\n",
    "    4. Sequential Model based optimization(Tuning scikit-learn estimator with skopt)\n",
    "    5. Optuna-Automate Hyperparameter Tuning\n",
    "    6. Genetic Algorithms (TPOT Classifier) -- Much efficient on Huge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdileepkumar\\documents\\02 python_practice\\03 softwares\\01 python\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\cdileepkumar\\documents\\02 python_practice\\03 softwares\\01 python\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Datasets\\diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling is not required in Random forest algorithms,bcoz things work on decision tress \n",
    "#and no much mathematical formulas will get applied on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Indepedent and depenedent Feature selection\n",
    "x=df.drop([\"Outcome\"],axis=1)\n",
    "y=df['Outcome']\n",
    "x.head()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check zero values in columns, which are not supposed to be\n",
    "import numpy as np\n",
    "df['Glucose']=np.where(df['Glucose'] == 0,df['Glucose'].mean(),df['Glucose'])\n",
    "df['BloodPressure']=np.where(df['BloodPressure'] == 0,df['BloodPressure'].mean(),df['BloodPressure'])\n",
    "df['Insulin']=np.where(df['Insulin'] == 0,df['Insulin'].mean(),df['Insulin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.182</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.189</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "      <td>125</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.698</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.261</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>62</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.441</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "660           10      162             84              0        0  27.7   \n",
       "69             4      146             85             27      100  28.9   \n",
       "85             2      110             74             29      125  32.4   \n",
       "219            5      112             66              0        0  37.8   \n",
       "712           10      129             62             36        0  41.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "660                     0.182   54  \n",
       "69                      0.189   27  \n",
       "85                      0.698   27  \n",
       "219                     0.261   41  \n",
       "712                     0.441   38  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=100)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=10).fit(x_train,y_train)\n",
    "y_pred=rf.predict(x_test)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=pd.Series(y_pred)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       101\n",
      "           1       0.57      0.45      0.51        53\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.66      0.64      0.64       154\n",
      "weighted avg       0.68      0.69      0.69       154\n",
      "\n",
      "0.6948051948051948\n",
      "[[83 18]\n",
      " [29 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The main parameters used by a Randomforest classifier\n",
    "\n",
    "Criterion -> The function used to evaluate the quality of a split\n",
    "\n",
    "max_depth -> maximum number of trees allowed in each tree\n",
    "\n",
    "max_features -> maximum number of features consideered when splitting a node\n",
    "\n",
    "min_sample_leaf -> minimum no.of samples which can be stored in a tree leaf\n",
    "\n",
    "min_sample_split -> minimum no.of samples necessary in a node to cause node splitting.\n",
    "\n",
    "n_estimators -> no.of trees in the ensamble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.80       101\n",
      "           1       0.61      0.51      0.56        53\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.69      0.67      0.68       154\n",
      "weighted avg       0.71      0.72      0.71       154\n",
      "\n",
      "0.7207792207792207\n",
      "[[84 17]\n",
      " [26 27]]\n"
     ]
    }
   ],
   "source": [
    "## Manual Hyperparameter Tuning\n",
    "rf=RandomForestClassifier(n_estimators=300,criterion='entropy',max_features='sqrt',min_samples_leaf=10,random_state=100).fit(x_train,y_train)\n",
    "y_pred=rf.predict(x_test)\n",
    "pd.Series(y_pred).value_counts()\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GridsearchCV vs Randomized searchCV\n",
    "1 million people living in Area A,B,C,D\n",
    "\n",
    "Find a person krish Naik in which area he is?\n",
    "\n",
    "Gridsearchcv -> search all areas A,B,C,D-> finalises that he lives in area B.\n",
    "\n",
    "-> There is no way to mention interations in gridsearchcv. It will calculate dynamically based on parameters.\n",
    "\n",
    "Takes all the combinations and permutations..\n",
    "\n",
    "Randomized searchCV -> Search some areas in less time and gives -> B,C -> give it to gridsearchcv -> it gives B\n",
    "\n",
    "Do some less iterations and get what you get ..\n",
    "\n",
    "Randomized searchCV -> Narrow down our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#Number of Trees in Randome Forest\n",
    "n_estimators=[int(x) for x in np.linspace(start=200,stop=2000,num=10)]\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "#Number of features to consider at every split\n",
    "max_features=['auto','sqrt','log2']\n",
    "#Maximum no.of levels in tree\n",
    "max_depth=[int(x) for x in np.linspace(10,1000,10)]\n",
    "#minimum no.of samples required to split a node\n",
    "min_samples_split=[2,5,10,14]\n",
    "#minimum no.of samples required at each leaf node\n",
    "min_samples_leaf=[1,2,4,6,8]\n",
    "#create the random gri\n",
    "random_grid={'n_estimators':n_estimators,'max_features':max_features,'max_depth':max_depth,'min_samples_split':min_samples_split,\n",
    "            'min_samples_leaf':min_samples_leaf,'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf_randomscv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=3,random_state=100,n_jobs=-1)\n",
    "rf_randomscv.fit(x_train,y_train)\n",
    "\n",
    "rf_randomscv.best_params_\n",
    "rf_randomscv.best_estimator_\n",
    "\n",
    "# This takes more time to execute\n",
    "\n",
    "#Important Paraments \n",
    "#n_iter = 100 -> No.of iterations\n",
    "#cv = 3 -> cross validation =3 means 3 times different samples will be taken from train data.\n",
    "#no.of fits = 100 *3 = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rf_randomscv.best_estimator_\n",
    "\n",
    "y_pred=best_random_grid.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_randomcv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-5ce3056307ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m param_grid = {\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m'criterion'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrf_randomcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'criterion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrf_randomcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'max_features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrf_randomcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_randomcv' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth': [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features': [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'], \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] - 1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'], \n",
    "                          rf_randomcv.best_params_['min_samples_split'] +1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] - 100, \n",
    "                     rf_randomcv.best_params_['n_estimators'], \n",
    "                     rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200]\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "#### Fit the grid_search to the data\n",
    "rf=RandomForestClassifier()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=10,n_jobs=-1,verbose=2)\n",
    "grid_search.fit(X_train,y_train)\n",
    "grid_search.best_estimator_\n",
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated Hyperparameter Tuning can be done by using techniques such as\n",
    "\n",
    "Bayesian Optimization\n",
    "Gradient Descent\n",
    "Evolutionary Algorithms\n",
    "Bayesian Optimization\n",
    "\n",
    "Bayesian optimization uses probability to find the minimum of a function.\n",
    "The final aim is to find the input value to a function which can gives us the lowest possible output value.\n",
    "It usually performs better than random,grid and manual search providing better performance in the testing phase and reduced optimization time. In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters to the function fmin.\n",
    "\n",
    "Objective Function = defines the loss function to minimize.\n",
    "\n",
    "Domain Space = defines the range of input values to test (in Bayesian Optimization this space creates a probability distribution for each of the used Hyperparameters).\n",
    "\n",
    "Optimization Algorithm = defines the search algorithm to use to select the best input values to use in each new iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
    "                                 max_features = space['max_features'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split'],\n",
    "                                 n_estimators = space['n_estimators'], \n",
    "                                 )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trials)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = {0: 'entropy', 1: 'gini'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200,5:1300,6:1500}\n",
    "\n",
    "\n",
    "print(crit[best['criterion']])\n",
    "print(feat[best['max_features']])\n",
    "print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best['min_samples_leaf']\n",
    "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]).fit(X_train,y_train)\n",
    "predictionforest = trainedforest.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictionforest))\n",
    "print(accuracy_score(y_test,predictionforest))\n",
    "print(classification_report(y_test,predictionforest))\n",
    "acc5 = accuracy_score(y_test,predictionforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
